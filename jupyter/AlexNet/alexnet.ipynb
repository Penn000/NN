{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## AlexNet网络结构\n",
    "\n",
    "![alexnet](./alex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(x, filters, n_filters, stride, name, padding='same', groups=1):\n",
    "    input_channels = int(x.get_shape()[-1])\n",
    "    \n",
    "    conv = lambda i, k: tf.nn.conv2d(i, k, strides=stride, padding=padding)\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', shape=[filters[1], filters[2], input_channels/groups, n_filters])\n",
    "        biases = tf.get_variable('biases', shape=[n_filters])\n",
    "    \n",
    "    if groups == 1:\n",
    "        layer = conv(x, weights)\n",
    "    else:\n",
    "        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)    \n",
    "        weights_groups = tf.split(axis=3, num_or_size_splits=groups, value=weights)\n",
    "        output_groups = [conv(i, k) for i, k in zip(input_groups, weights_groups)]\n",
    "        layer = tf.concat(axis=3, values=output_groups)\n",
    "    \n",
    "    layer = tf.reshape(tf.nn.bias_add(layer, biases), tf.shape(layer))\n",
    "    layer = tf.nn.relu(layer, name=scope.name)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(x, in_size, out_size, name):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', shape=[in_size, out_size], trainable=True)\n",
    "        biases = tf.get_variable('biases', shape=[out_size], trainable=True)\n",
    "        \n",
    "    layer = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_layer(x, filters, stride, name, padding='SAME'):\n",
    "    return tf.nn.max_pool(x, ksize=filters, strides=stride, padding=padding, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrn(x, radius, alpha, beta, name, bias=1.0):\n",
    "    return tf.nn.local_response_normalization(x, depth_radius=radius, alpha=alpha, beta=beta, bias=bias, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(x, keep_prob):\n",
    "    return tf.nn.dropout(x, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = 0.5\n",
    "n_class = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alex_net(X):\n",
    "    # 1st layer\n",
    "    conv1 = conv_layer(X, [1, 11, 11, 1], 96, [1, 4, 4, 1], padding='VALID', name='conv1')\n",
    "    norm1 = lrn(conv1, 2, 2e-5, 0.75, name='norm1')\n",
    "    pool1 = max_pool_layer(norm1, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    conv2 = conv_layer(pool1, [1, 5, 5, 1], 256, [1, 1, 1, 1], groups=2, name='conv2')\n",
    "    norm2 = lrn(conv2, 2, 2e-5, 0.75, name='norm2')\n",
    "    pool2 = max_pool_layer(norm2, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    \n",
    "    # 3rd layer\n",
    "    conv3 = conv_layer(pool2, [1, 3, 3, 1], 384, [1, 1, 1, 1], name='conv3')\n",
    "    \n",
    "    # 4th layer\n",
    "    conv4 = conv_layer(conv3, [1, 3, 3, 1], 384, [1, 1, 1, 1], groups=2, name='conv4')\n",
    "    \n",
    "    # 5th layer\n",
    "    conv5 = conv_layer(conv4, [1, 3, 3, 1], 256, [1, 1, 1, 1], groups=2, name='conv5')\n",
    "    pool5 = max_pool_layer(conv5, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    \n",
    "    # 6th layer\n",
    "    flatten = tf.reshape(pool5, [-1, 6*6*256])\n",
    "    fc6 = fc_layer(flatten, 6*6*256, 4096, name='fc6')\n",
    "    relu6 = tf.nn.relu(fc6)\n",
    "    dropout6 = dropout(relu6, keep_prob)\n",
    "    \n",
    "    # 7th layer\n",
    "    fc7 = fc_layer(dropout6, 4096, 4096, name='fc7')\n",
    "    relu7 = tf.nn.relu(fc7)\n",
    "    dropout7 = dropout(relu7, keep_prob)\n",
    "    \n",
    "    # 8th layer\n",
    "    fc8 = fc_layer(dropout7, 4097, n_classes, name='fc8')\n",
    "    \n",
    "    return fc8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
