{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph\n",
    "\n",
    "### 例1. 矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning \n",
    "\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "'''删掉以前的summary，以免重合'''\n",
    "log_dir = 'logs/'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('matmul_graph') as scope:\n",
    "    mat1 = tf.constant([[1.0, 2.0]], name='mat1')\n",
    "    mat2 = tf.constant([[3.0], [4.0]], name='mat2')\n",
    "    mat3 = tf.matmul(mat1, mat2, name='mat3')\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "打开tensorboard\n",
    "\n",
    "1. 在终端输入`tensorboard --logdir ./logs/`开启tensorboard\n",
    "2. 在浏览器输入`localhost:6006`打开tensorboard\n",
    "\n",
    "上面例子的graph如下图所示：\n",
    "\n",
    "![matmul_graph](./matmul_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例2. 线性拟合\n",
    "\n",
    "运行前请`restart the kernel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "'''删掉以前的summary，以免重合'''\n",
    "log_dir = 'logs/'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \t weight: [0.6205399] \t bias: [-0.1242687]\n",
      "step: 10 \t weight: [0.48994166] \t bias: [-0.00800802]\n",
      "step: 20 \t weight: [0.40655446] \t bias: [0.03940928]\n",
      "step: 30 \t weight: [0.35977545] \t bias: [0.06600952]\n",
      "step: 40 \t weight: [0.33353314] \t bias: [0.08093185]\n",
      "step: 50 \t weight: [0.31881163] \t bias: [0.08930304]\n",
      "step: 60 \t weight: [0.31055304] \t bias: [0.09399917]\n",
      "step: 70 \t weight: [0.3059201] \t bias: [0.09663364]\n",
      "step: 80 \t weight: [0.3033211] \t bias: [0.0981115]\n",
      "step: 90 \t weight: [0.30186307] \t bias: [0.0989406]\n",
      "step: 100 \t weight: [0.30104518] \t bias: [0.09940568]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = 0.3 * x_data + 0.1\n",
    "\n",
    "weight = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name='weight')\n",
    "bias = tf.Variable(tf.zeros([1]), name='biases')\n",
    "\n",
    "with tf.name_scope('product'):\n",
    "    y_prediction = weight * x_data + bias\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_data-y_prediction))\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(101):\n",
    "        sess.run(train)\n",
    "        if step %10==0 :\n",
    "            print('step:', step, '\\t weight:', sess.run(weight), '\\t bias:', sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./linear.png)\n",
    "\n",
    "![](./linear2.png)\n",
    "\n",
    "![](./linear3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar\n",
    "\n",
    "### 例1. 线性拟合\n",
    "\n",
    "运行前请`restart the kernel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 不打印 warning \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "'''删掉以前的summary，以免重合'''\n",
    "log_dir = 'logs/'\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \tweight: [4.949478] \t bias: [-3.2257266] \t loss: 2.6037736\n",
      "step: 10 \tweight: [3.0910137] \t bias: [-1.3632321] \t loss: 0.5651975\n",
      "step: 20 \tweight: [1.8533778] \t bias: [-0.7143817] \t loss: 0.17507751\n",
      "step: 30 \tweight: [1.1645539] \t bias: [-0.35325542] \t loss: 0.054232586\n",
      "step: 40 \tweight: [0.7811794] \t bias: [-0.15226556] \t loss: 0.016799266\n",
      "step: 50 \tweight: [0.5678071] \t bias: [-0.04040189] \t loss: 0.0052037956\n",
      "step: 60 \tweight: [0.44905174] \t bias: [0.02185739] \t loss: 0.0016119446\n",
      "step: 70 \tweight: [0.38295683] \t bias: [0.05650864] \t loss: 0.0004993215\n",
      "step: 80 \tweight: [0.3461708] \t bias: [0.07579427] \t loss: 0.00015467181\n",
      "step: 90 \tweight: [0.325697] \t bias: [0.08652797] \t loss: 4.791166e-05\n",
      "step: 100 \tweight: [0.31430203] \t bias: [0.09250195] \t loss: 1.4841261e-05\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = 0.3 * x_data + 0.1\n",
    "\n",
    "weight = tf.Variable(tf.random_uniform([1], -10.0, 10.0), name='weight')\n",
    "bias = tf.Variable(tf.zeros([1]), name='biases')\n",
    "\n",
    "with tf.name_scope('product'):\n",
    "    y_prediction = weight * x_data + bias\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_data-y_prediction))\n",
    "    # loss_summary = tf.summary.scalar('loss', loss)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(log_dir)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(101):\n",
    "        sess.run(train)\n",
    "        writer.add_summary(sess.run(loss), step)\n",
    "        if step %10==0 :\n",
    "            print('step:', step, '\\tweight:', sess.run(weight), '\\t bias:', sess.run(bias), '\\t loss:', sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scalars](./scalars.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
